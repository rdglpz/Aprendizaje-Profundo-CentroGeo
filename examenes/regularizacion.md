
Aprendizaje Profundo
Re-Evaluación Unidad 1-3.
CentroGeo - Maestría en Ciencias de Información Geoespacial

Prof. Dr. Rodrigo López Farías
Alumno:  




1. Menciona un avance y una limitación en los modelos de aprendizaje automático de cada una de las 3 olas vistas en clase. (10/100)


2. ¿Cuáles son las principales características de los dos tipos principales de aprendizaje automático? (10/100)


3. Da un ejemplo de una función $f(x)$ que tenga un punto crítico en un punto de silla. Describe los pasos generales para identificarlo. (10/100)


4. Encontrar la dirección de máximo descenso de gradiente para la función $f({x}) = ((mx+b)-1)^2 $ con respecto a $x=10$ y parámetros $\theta = [m,b]$


	1. $[m,b]^T = [1,1]^T$ (10/100)
	2. $[m,b] = [0,0]^T$ (10/100)



6. A partir de la Serie de Taylor: (20/100)

$$f(x)=\sum^\infty_{n=0} \frac{f^{(n)}(a)}{n!}(x-a)^n$$

Truncando hasta el orden n=2, 

$$f({x}) \approx f({x_0})+({x}-{x}_0) {g} + 1/2 ({x}-{x}_0)^2 {h}$$

donde:


$f(x)=x^3$
${g}$ : Es la derivada evaluada en ${x}_0$.
${h}$: La segunda derivada evaluada en ${x}_0$.

Sustituyendo
${x}$  = ${x_0}-\epsilon^* {g}$

Encontrar el $\epsilon^*$ óptimo que hace $f(x_0-\epsilon^* g) = 0$

dado $x_0 = -3.5$



describir los pasos necesarios para llegar a la solución de la tasa de aprendizaje $\epsilon^*$



6 . Escribir en pseudocódigo el algoritmo de descenso de gradiente. Realizar la primera iteración para $f(x) = (mx+b-1)^2$ con respecto a los parametros $\theta = {m,b}$ con $x=0$ y $\epsilon=0.9$ (15/100)

7 . Dada la función de prueba:

$$f(x,y) = (2ax+ay^2)- xy^2 $$


Calcular el gradiente. (15/100) 

Y su matriz Hessiana. (20/100) 



